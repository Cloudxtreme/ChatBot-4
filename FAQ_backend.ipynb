{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "import nltk\n",
    "import sys\n",
    "import time\n",
    "from gensim import corpora, models, similarities\n",
    "from six import iteritems\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexTokenizer\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "TEMP_FOLDER = tempfile.gettempdir()\n",
    "\n",
    "#load answers into memory\n",
    "answer_lines=[]\n",
    "for line in open ('answers.txt'):\n",
    "    answer_lines.append(line)\n",
    "\n",
    "#Create corpus\n",
    "class Corpus(object):\n",
    "    def __iter__(self):\n",
    "        for q_line, a_line in zip(open('questions.txt'), open('answers.txt')):\n",
    "            line = q_line.lower().split()+a_line.lower().split()\n",
    "            yield dictionary.doc2bow(line)\n",
    "corpus = Corpus()\n",
    "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'corpus.mm'), corpus)\n",
    "\n",
    "#Create dictionary\n",
    "nltk.extract_rels\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "stoplist = set(stopwords.words('english'))\n",
    "#TAG NOT COMPLETE!!!!!\n",
    "tags=['WRB', 'WP', 'WP$', 'WPT', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'NNP', 'NNPS', 'NN', 'NNS', 'JJ', 'JJS', 'JJ']\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "text_cleaned = []\n",
    "for q_line, a_line in zip(open('questions.txt'), open('answers.txt')):\n",
    "    line_cleaned = []\n",
    "    tokens = tokenizer.tokenize(q_line.lower()+a_line.lower())\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    for i, j in pos:\n",
    "        if (i not in stopliest):\n",
    "            if (j in tags):\n",
    "                line_cleaned.append(lemma.lemmatize(i))\n",
    "                line_cleaned.append(i)\n",
    "    text_cleaned.append(line_cleaned)\n",
    "dictionary=corpora.Dictionary(text_cleaned)\n",
    "dictionary.compactify()\n",
    "dictionary.save(os.path.join(TEMP_FOLDER, 'dictionary.dict'))\n",
    "\n",
    "#Load dictionary and corpus\n",
    "dictionary = corpora.Dictionary.load(os.path.join(TEMP_FOLDER, 'dictionary.dict'))\n",
    "corpus = corpora.MmCorpus(os.path.join(TEMP_FOLDER, 'corpus.mm'))\n",
    "\n",
    "#Train tf-idf model and lsi model\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=8)\n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "index.save(os.path.join(TEMP_FOLDER, 'index.index'))\n",
    "\n",
    "#Continue training with additonal training data\n",
    "#lsi.add_documents(another_tfidf_corpus)\n",
    "#corpus_lsi= lsi[corpus_tfidf] \n",
    "\n",
    "#Load similarity matrix\n",
    "index=similarities.MatrixSimilarity.load(os.path.join(TEMP_FOLDER, 'index.index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user query and match \n",
    "user_query=input(\"How can I help you? \")\n",
    "tokens = [lemma.lemmatize(word) for word in tokenizer.tokenize(user_query)]\n",
    "vec_bow=dictionary.doc2bow(tokens)\n",
    "vec_lsi=lsi[vec_bow]\n",
    "sims = lsi[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item:-item[1])\n",
    "match=sims[0][0]\n",
    "answer = nltk.sent_tokenize(answer_lines[match])\n",
    "if (len(answer)<3):\n",
    "    for line in answer:\n",
    "        time.sleep(3)\n",
    "        system.stdout.write(line+'\\n')\n",
    "else:\n",
    "    time.sleep(3)\n",
    "    system.stdout.write(answer[0]+'\\n')\n",
    "    time.sleep(3)\n",
    "    system.stdout.write(answer[1]+'...'+'\\n')\n",
    "    user_response=input(\"Is this answer relevant?(yes/no)\")\n",
    "    if (user_response=='yes'):\n",
    "        time.sleep(3)\n",
    "        system.stdout.write('Great! Here is the rest of the answer:')\n",
    "        for i in range(2, len(answer)):\n",
    "            time.sleep(3)\n",
    "            system.stdout.write(answer[1]+'\\n')\n",
    "    else:\n",
    "        system.stdout.write('Sorry. You will need to ask someone else.')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
